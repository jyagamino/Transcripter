{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "DzPvk-FC_sXj",
        "outputId": "f8bdfb38-8ab3-4e15-f50e-5f875e099283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyannote.audio in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.11/dist-packages (1.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.28.1)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.5.0.post0)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (5.1.3)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.8.1)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (13.9.4)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (3.0.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.13.1)\n",
            "Requirement already satisfied: speechbrain>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (1.0.2)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.2.2)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (0.12.0)\n",
            "Requirement already satisfied: torchaudio>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.audio) (1.6.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote.audio) (0.14.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.1->pyannote.audio) (2.5.0.post0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.14.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.6.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.10.0)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (4.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6->pyannote.audio) (4.25.6)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (3.11.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (75.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.15.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.39)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio) (1.18.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.17.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyannote.audio openai-whisper ffmpeg torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "l5QwBEsg_sXk",
        "outputId": "7cad3b5e-e69d-49f6-e098-afa9b80e6f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "def mount_google_drive():\n",
        "    \"\"\"Google Driveをマウントします\"\"\"\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "mount_google_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "EAnyZxba_sXk",
        "outputId": "50b7d262-e6b8-4635-ba8a-31a330f89589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "対象ファイル: ['/content/drive/My Drive/TranscriptionFolder/ZeroPlus_student-opinion-meeting.mp4', '/content/drive/My Drive/TranscriptionFolder/ZeroPlus_student-opinion-meeting.mp3']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def list_media_files(folder_path):\n",
        "    \"\"\"指定フォルダ内のMP4またはMP3ファイルをリストアップ\"\"\"\n",
        "    return [\n",
        "        os.path.join(folder_path, f)\n",
        "        for f in os.listdir(folder_path)\n",
        "        if f.endswith(('.mp4', '.mp3'))\n",
        "    ]\n",
        "\n",
        "# Google Drive内の対象フォルダを指定\n",
        "target_folder = \"/content/drive/My Drive/TranscriptionFolder\"\n",
        "media_files = list_media_files(target_folder)\n",
        "\n",
        "if not media_files:\n",
        "    print(\"対象のMP4またはMP3ファイルが見つかりませんでした。\")\n",
        "else:\n",
        "    print(f\"対象ファイル: {media_files}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "HrEe8ikX_sXk"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_mp4_to_mp3(mp4_file):\n",
        "    \"\"\"MP4ファイルをMP3ファイルに変換\"\"\"\n",
        "    mp3_file = mp4_file.replace(\".mp4\", \".mp3\")\n",
        "    command = f'ffmpeg -i \"{mp4_file}\" -q:a 0 -map a \"{mp3_file}\" -y'\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "    print(f\"Converted {mp4_file} to {mp3_file}\")\n",
        "    return mp3_file\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio.pipelines import SpeakerDiarization\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "HUGGINGFACE_TOKEN = userdata.get('HUGGINGFACE_TOKEN')\n",
        "\n",
        "# Hugging Faceのトークンを入力してください\n",
        "login(token=HUGGINGFACE_TOKEN)\n",
        "\n",
        "\n",
        "def diarize_audio(file_path):\n",
        "    \"\"\"音声ファイルの話者分離を実行\"\"\"\n",
        "    pipeline = SpeakerDiarization.from_pretrained(\"pyannote/speaker-diarization@2.1\")\n",
        "    diarization = pipeline(file_path)\n",
        "\n",
        "    # 話者ごとにセグメントを分ける\n",
        "    segments = []\n",
        "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "        segments.append({\n",
        "            'start': turn.start,\n",
        "            'end': turn.end,\n",
        "            'speaker': speaker\n",
        "        })\n",
        "    return segments\n"
      ],
      "metadata": {
        "id": "HQqch72OGMew"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "RCgjj_DJ_sXl"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import torch\n",
        "\n",
        "# Whisperモデルをロード\n",
        "model = whisper.load_model(\"small\", device=\"cpu\")  # 必要に応じてモデルサイズを変更\n",
        "\n",
        "# モデルのすべてのパラメータをFP32（単精度浮動小数点）に変換\n",
        "for param in model.parameters():\n",
        "    param.data = param.data.to(dtype=torch.float32)\n",
        "    if param.grad is not None:\n",
        "        param.grad.data = param.grad.data.to(dtype=torch.float32)\n",
        "\n",
        "def transcribe_with_speaker_segments(segments, audio_path, model):\n",
        "    \"\"\"話者分離後、各セグメントごとに文字起こしを行う\"\"\"\n",
        "    transcribed_text = \"\"\n",
        "    for segment in segments:\n",
        "        start = segment['start']\n",
        "        end = segment['end']\n",
        "        speaker = segment['speaker']\n",
        "        # セグメントごとの音声を切り出し、文字起こし\n",
        "        audio_segment_path = f\"/content/segment_{start}_{end}.wav\"\n",
        "        command = f\"ffmpeg -ss {start} -to {end} -i {audio_path} -acodec pcm_s16le -ar 16000 -ac 1 {audio_segment_path}\"\n",
        "        subprocess.run(command, shell=True, check=True)\n",
        "\n",
        "        # Whisperで文字起こし\n",
        "        result = model.transcribe(audio_segment_path)\n",
        "        transcribed_text += f\"\\n\\n{speaker}: {result['text']}\"\n",
        "\n",
        "    return transcribed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ANPmlWKf_sXl",
        "outputId": "3b3a22a3-b9bc-4039-f1bc-4485677858cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted /content/drive/My Drive/TranscriptionFolder/ZeroPlus_student-opinion-meeting.mp4 to /content/drive/My Drive/TranscriptionFolder/ZeroPlus_student-opinion-meeting.mp3\n",
            "Processing: /content/drive/My Drive/TranscriptionFolder/ZeroPlus_student-opinion-meeting.mp3\n",
            "\n",
            "Could not download 'pyannote/speaker-diarization' pipeline.\n",
            "It might be because the pipeline is private or gated so make\n",
            "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
            "create your access token and retry with:\n",
            "\n",
            "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
            "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
            "\n",
            "If this still does not work, it might be because the pipeline is gated:\n",
            "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-744a9e7c366d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing: {audio_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 音声ファイルを話者ごとに分ける\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiarize_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# 話者分離後、各セグメントを文字起こし\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtranscribed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_with_speaker_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-040f7bd22c5a>\u001b[0m in \u001b[0;36mdiarize_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\"音声ファイルの話者分離を実行\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeakerDiarization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyannote/speaker-diarization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdiarization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 話者ごとにセグメントを分ける\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "# MP4ファイルをMP3に変換\n",
        "converted_mp3_files = []\n",
        "for media_file in media_files:\n",
        "    if media_file.endswith(\".mp4\"):\n",
        "        try:\n",
        "            converted_mp3_files.append(convert_mp4_to_mp3(media_file))\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error converting {media_file}: {e}\")\n",
        "    elif media_file.endswith(\".mp3\"):\n",
        "        converted_mp3_files.append(media_file)\n",
        "\n",
        "# テキスト化を実行\n",
        "if converted_mp3_files:\n",
        "    for audio_file in converted_mp3_files:\n",
        "        print(f\"Processing: {audio_file}\")\n",
        "        # 音声ファイルを話者ごとに分ける\n",
        "        segments = diarize_audio(audio_file)\n",
        "        # 話者分離後、各セグメントを文字起こし\n",
        "        transcribed_text = transcribe_with_speaker_segments(segments, audio_file, model)\n",
        "\n",
        "        # 結果をファイルに保存\n",
        "        output_file = audio_file.replace('.mp3', '.txt')\n",
        "        with open(output_file, \"w\") as f:\n",
        "            f.write(transcribed_text)\n",
        "        print(f\"Saved transcription to: {output_file}\")\n",
        "else:\n",
        "    print(\"テキスト化するファイルがありません。\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}