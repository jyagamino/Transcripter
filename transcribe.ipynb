{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai-whisper ffmpeg torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "def mount_google_drive():\n",
    "    \"\"\"Google Driveをマウントします\"\"\"\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted successfully.\")\n",
    "\n",
    "mount_google_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def extract_audio_from_video(video_file, output_audio_file):\n",
    "    \"\"\"MP4ファイルから音声を抽出します\"\"\"\n",
    "    command = f\"ffmpeg -i {video_file} -q:a 0 -map a {output_audio_file} -y\"\n",
    "    subprocess.run(command, shell=True)\n",
    "    print(f\"Audio extracted to {output_audio_file}\")\n",
    "\n",
    "# 例: 動画ファイルを音声ファイルに変換\n",
    "video_file = \"/content/drive/My Drive/TranscriptionFolder/sample_video.mp4\"  # Google DriveのMP4ファイルパス\n",
    "output_audio_file = video_file.replace(\".mp4\", \".mp3\")\n",
    "extract_audio_from_video(video_file, output_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def split_audio_file(audio_file, output_dir, segment_length=300):\n",
    "    \"\"\"音声ファイルを指定された長さ（秒）で分割\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    command = f\"ffmpeg -i {audio_file} -f segment -segment_time {segment_length} -c copy {output_dir}/output%03d.mp3\"\n",
    "    subprocess.run(command, shell=True)\n",
    "    print(f\"Audio split into segments in {output_dir}\")\n",
    "\n",
    "# 例: 5分（300秒）ごとに分割\n",
    "split_audio_file(output_audio_file, \"/content/drive/My Drive/TranscriptionFolder/audio_segments\", segment_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "def list_audio_files(folder_path):\n",
    "    \"\"\"指定フォルダ内の音声ファイルをリストアップします\"\"\"\n",
    "    return [\n",
    "        os.path.join(folder_path, f)\n",
    "        for f in os.listdir(folder_path)\n",
    "        if f.endswith('.mp3')\n",
    "    ]\n",
    "\n",
    "def transcribe_files(files, model):\n",
    "    \"\"\"ファイルごとにテキスト化を実行し、結果を保存します\"\"\"\n",
    "    for file_path in files:\n",
    "        print(f\"Processing: {file_path}\")\n",
    "        result = model.transcribe(file_path)\n",
    "        \n",
    "        # テキスト結果を保存\n",
    "        output_file = file_path.replace('.mp3', '.txt')\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "        print(f\"Saved transcription to: {output_file}\")\n",
    "\n",
    "# 分割された音声ファイルをリストアップ\n",
    "segment_folder = \"/content/drive/My Drive/TranscriptionFolder/audio_segments\"\n",
    "audio_files = list_audio_files(segment_folder)\n",
    "\n",
    "# Whisperモデルをロード\n",
    "model = whisper.load_model(\"small\")  # 必要に応じてモデルサイズを変更\n",
    "\n",
    "# テキスト化を実行\n",
    "if audio_files:\n",
    "    transcribe_files(audio_files, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"すべてのファイルをテキスト化しました！\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
